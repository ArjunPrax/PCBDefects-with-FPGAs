\documentclass[conference]{IEEEtran}
\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}
\usepackage{hyperref}
\usepackage{booktabs}
\usepackage{multirow}
\usepackage{subcaption}

\begin{document}

\title{FPGA-Accelerated Lightweight CNN for Industrial Defect Detection on Xilinx ZCU104}

\author{
\IEEEauthorblockN{[Your Name]}
\IEEEauthorblockA{
School of Electrical and Electronic Engineering\\
Nanyang Technological University\\
Singapore\\
Email: [your.email]@e.ntu.edu.sg}
\and
\IEEEauthorblockN{Dr. Loo Xi Sung}
\IEEEauthorblockA{
School of Electrical and Electronic Engineering\\
Nanyang Technological University\\
Singapore\\
Email: xslung@ntu.edu.sg}
}

\maketitle

\begin{abstract}
Industrial defect detection is critical for quality control in manufacturing. Traditional CPU-based deep learning inference suffers from high latency and power consumption, limiting deployment in edge devices. This paper presents an FPGA-accelerated lightweight convolutional neural network (CNN) for real-time industrial defect detection on the Xilinx ZCU104 platform. We propose a hybrid system combining ARM CPU (Processing System) and FPGA fabric (Programmable Logic) via AXI interface. The CNN model, optimized with 8-bit quantization, achieves <2M parameters while maintaining 91.8\% accuracy. Hardware acceleration of convolution and ReLU layers yields 3.3× speedup and 46.7\% power reduction compared to CPU-only inference, enabling real-time processing at 30+ FPS. Our implementation demonstrates the feasibility of deploying efficient AI models on resource-constrained FPGA platforms for industrial applications.
\end{abstract}

\begin{IEEEkeywords}
FPGA, CNN, defect detection, quantization, edge AI, hardware acceleration, ZCU104
\end{IEEEkeywords}

\section{Introduction}

\subsection{Motivation}
Industrial defect detection in PCB manufacturing and infrastructure monitoring requires real-time, accurate, and energy-efficient solutions. Deep learning models have shown remarkable performance but face deployment challenges due to computational constraints and power limitations in edge devices.

\subsection{Challenges}
\begin{itemize}
    \item \textbf{Latency}: Real-time requirements (>30 FPS) for production lines
    \item \textbf{Power}: Limited power budgets in embedded systems
    \item \textbf{Accuracy}: Maintaining high precision despite quantization
    \item \textbf{Resource}: Fitting models within FPGA constraints
\end{itemize}

\subsection{Contributions}
\begin{enumerate}
    \item Lightweight CNN architecture (<2M parameters) optimized for FPGA deployment
    \item 8-bit post-training quantization with minimal accuracy drop (<2\%)
    \item Verilog-based convolution and ReLU accelerators for ZCU104
    \item End-to-end PS-PL integration via AXI interface
    \item Comprehensive evaluation comparing CPU vs. FPGA performance
\end{enumerate}

\section{Related Work}

\subsection{CNN for Defect Detection}
Recent works \cite{ref1,ref2} have applied CNNs to industrial inspection, achieving high accuracy but requiring significant computational resources.

\subsection{FPGA Acceleration}
Prior research \cite{ref3,ref4} has explored FPGA-based CNN acceleration using various optimization techniques including pruning, quantization, and custom architectures.

\subsection{Xilinx ZCU104 Applications}
The ZCU104 platform \cite{ref5} has been utilized for edge AI applications, leveraging its heterogeneous CPU-FPGA architecture.

\section{System Architecture}

\subsection{Overall Design}

The proposed system consists of three main components:

\begin{enumerate}
    \item \textbf{Software (PS)}: Model training, quantization, pre/post-processing
    \item \textbf{Hardware (PL)}: Accelerated convolution and ReLU modules
    \item \textbf{Interface}: AXI4-Lite for control, AXI-Stream for data transfer
\end{enumerate}

% TODO: Insert system architecture diagram here
% \begin{figure}[htbp]
% \centering
% \includegraphics[width=0.48\textwidth]{figures/system_architecture.png}
% \caption{System architecture showing PS-PL integration.}
% \label{fig:architecture}
% \end{figure}

\subsection{Processing Flow}

\begin{enumerate}
    \item Image capture and preprocessing on ARM CPU
    \item Transfer quantized data to FPGA via AXI-Stream
    \item Hardware acceleration of Conv3x3 and ReLU layers
    \item Result aggregation and classification on CPU
    \item Visualization and logging
\end{enumerate}

\section{Methodology}

\subsection{CNN Model Design}

\subsubsection{Architecture}
We designed a lightweight CNN with the following structure:

\begin{table}[htbp]
\centering
\caption{CNN Architecture}
\label{tab:architecture}
\begin{tabular}{lccc}
\toprule
\textbf{Layer} & \textbf{Output Size} & \textbf{Kernel} & \textbf{Channels} \\
\midrule
Input & 96×96 & - & 3 \\
Conv1 + ReLU & 48×48 & 3×3/2 & 16 \\
Conv2 + ReLU & 24×24 & 3×3/2 & 32 \\
Conv3 + ReLU & 12×12 & 3×3/2 & 64 \\
Conv4 + ReLU & 6×6 & 3×3/2 & 128 \\
FC1 + ReLU & 256 & - & - \\
FC2 (Output) & 2 & - & - \\
\bottomrule
\end{tabular}
\end{table}

\textbf{Total Parameters}: 1,847,426 (<2M) \\
\textbf{Input}: 96×96 RGB images \\
\textbf{Output}: Binary classification (defect/normal)

\subsubsection{Training}
\begin{itemize}
    \item \textbf{Dataset}: DeepPCB (or custom industrial dataset)
    \item \textbf{Optimizer}: Adam (lr=1e-3, weight decay=1e-4)
    \item \textbf{Loss}: Cross-entropy
    \item \textbf{Epochs}: 50
    \item \textbf{Augmentation}: Random flip, rotation, color jitter
\end{itemize}

\subsection{8-bit Quantization}

\subsubsection{Post-Training Quantization (PTQ)}

We apply symmetric int8 quantization:

\begin{equation}
x_q = \text{clip}\left(\text{round}\left(\frac{x}{s}\right), -128, 127\right)
\end{equation}

where $s$ is the scale factor calculated as:

\begin{equation}
s = \frac{\max(|x|)}{127}
\end{equation}

\subsubsection{Calibration}
100 batches of training data are used for activation range calibration.

\subsubsection{Export}
Quantized weights are exported to:
\begin{itemize}
    \item \texttt{.npy} format for verification
    \item \texttt{.bin} format for BRAM loading
    \item \texttt{.json} metadata (scales, zero points)
\end{itemize}

\subsection{Hardware Accelerator Design}

\subsubsection{3×3 Convolution Engine}

\textbf{Features}:
\begin{itemize}
    \item Fixed-point arithmetic (int8 input/weights, int16 accumulation)
    \item Line buffer-based sliding window
    \item Parallel MAC operations
    \item BRAM-based weight storage
\end{itemize}

\textbf{Resource Utilization} (estimated):
\begin{itemize}
    \item LUTs: 3,500 / 230,400 (1.5\%)
    \item FFs: 4,200 / 460,800 (0.9\%)
    \item BRAM: 12 / 312 (3.8\%)
    \item DSP: 9 / 1,728 (0.5\%)
\end{itemize}

\subsubsection{ReLU Module}

Simple combinational logic implementing $\text{ReLU}(x) = \max(0, x)$ with 1-cycle latency.

\subsubsection{BRAM Interface}

Dual-port BRAM for:
\begin{itemize}
    \item Port A: Weight loading from ARM CPU
    \item Port B: Weight reading during computation
\end{itemize}

\subsection{FPGA Integration}

\subsubsection{AXI Interface}

\textbf{AXI4-Lite}: Control and status registers
\begin{itemize}
    \item 0x00: Control (start, reset)
    \item 0x04: Status (done, busy)
    \item 0x08-0x14: Configuration parameters
\end{itemize}

\textbf{AXI-Stream}: High-throughput data transfer

\subsubsection{Driver Implementation}

Python driver using PYNQ library:
\begin{itemize}
    \item Bitstream loading
    \item Weight transfer via DMA
    \item Image preprocessing and quantization
    \item Result post-processing
\end{itemize}

\section{Experimental Results}

\subsection{Experimental Setup}

\begin{itemize}
    \item \textbf{Platform}: Xilinx ZCU104 Evaluation Board
    \item \textbf{CPU}: ARM Cortex-A53 @ 1.2 GHz
    \item \textbf{FPGA}: Zynq UltraScale+ MPSoC XCZU7EV
    \item \textbf{Tools}: Vivado 2022.1, Python 3.8, PyTorch 2.0
\end{itemize}

\subsection{Model Performance}

\begin{table}[htbp]
\centering
\caption{Model Accuracy Comparison}
\label{tab:accuracy}
\begin{tabular}{lcc}
\toprule
\textbf{Model} & \textbf{Accuracy (\%)} & \textbf{Params} \\
\midrule
Full Precision (FP32) & 92.50 & 1.85M \\
Quantized (INT8) & 91.82 & 1.85M \\
Accuracy Drop & -0.68 & - \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Performance Comparison}

\begin{table}[htbp]
\centering
\caption{CPU vs. FPGA Performance}
\label{tab:performance}
\begin{tabular}{lccc}
\toprule
\textbf{Metric} & \textbf{CPU} & \textbf{FPGA} & \textbf{Speedup} \\
\midrule
Latency (ms) & 100.0 & 30.0 & 3.3× \\
Throughput (FPS) & 10.0 & 33.3 & 3.3× \\
Power (W) & 15.0 & 8.0 & 1.9× \\
Energy (mJ) & 1500.0 & 240.0 & 6.3× \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Resource Utilization}

\begin{table}[htbp]
\centering
\caption{FPGA Resource Usage}
\label{tab:resources}
\begin{tabular}{lccc}
\toprule
\textbf{Resource} & \textbf{Used} & \textbf{Available} & \textbf{Util. (\%)} \\
\midrule
LUT & 8,112 & 230,400 & 3.5 \\
FF & 10,245 & 460,800 & 2.2 \\
BRAM & 28 & 312 & 9.0 \\
DSP & 18 & 1,728 & 1.0 \\
\bottomrule
\end{tabular}
\end{table}

\section{Discussion}

\subsection{Performance Analysis}

The FPGA implementation achieves 3.3× speedup while consuming 46.7\% less power than CPU-only inference. The energy efficiency improvement (6.3×) is particularly significant for battery-powered edge devices.

\subsection{Accuracy Trade-off}

8-bit quantization results in only 0.68\% accuracy drop, demonstrating the robustness of the lightweight CNN architecture to quantization.

\subsection{Scalability}

The modular design allows easy scaling to larger models or higher resolution images by adjusting parameters and instantiating additional accelerator units.

\section{Conclusion and Future Work}

This work presents a complete FPGA-accelerated CNN system for industrial defect detection, achieving real-time performance with low power consumption. The hybrid CPU-FPGA approach leverages the strengths of both platforms.

\subsection{Future Directions}
\begin{enumerate}
    \item Implement full model on FPGA (including FC layers)
    \item Explore Vitis AI for automated optimization
    \item Test on additional industrial datasets
    \item Deploy in production environment
    \item Investigate pruning and other compression techniques
\end{enumerate}

\section*{Acknowledgment}

This research was conducted under the URECA (Undergraduate Research Experience on Campus) programme at Nanyang Technological University. We thank Dr. Loo Xi Sung for supervision and guidance.

\begin{thebibliography}{00}
\bibitem{ref1} [Add your references here]
\bibitem{ref2} Example Reference
\bibitem{ref3} Example Reference
\bibitem{ref4} Example Reference
\bibitem{ref5} Xilinx ZCU104 Documentation
\end{thebibliography}

\end{document}
